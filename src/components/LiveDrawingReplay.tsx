import React, { useEffect, useRef } from 'react';
import type { LiveDrawingData } from '../types/annotation';

interface LiveDrawingReplayProps {
  videoElement: HTMLVideoElement;
  liveDrawingData: LiveDrawingData;
  startTimestamp: number;
  isActive: boolean;
}

export const LiveDrawingReplay: React.FC<LiveDrawingReplayProps> = ({
  videoElement,
  liveDrawingData,
  startTimestamp,
  isActive
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number | null>(null);

  console.log('ğŸ¬ LiveDrawingReplay render:', {
    isActive,
    hasCanvas: !!canvasRef.current,
    hasVideoElement: !!videoElement,
    dataStrokes: liveDrawingData?.strokes?.length,
    startTimestamp
  });

  useEffect(() => {
    console.log('ğŸ¬ LiveDrawingReplay useEffect triggered:', {
      isActive,
      hasCanvas: !!canvasRef.current,
      canvasWidth: liveDrawingData.canvasWidth,
      canvasHeight: liveDrawingData.canvasHeight
    });

    if (!isActive || !canvasRef.current) {
      console.log('âŒ LiveDrawingReplay: conditions not met');
      return;
    }

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // è®¾ç½®canvaså°ºå¯¸
    canvas.width = liveDrawingData.canvasWidth;
    canvas.height = liveDrawingData.canvasHeight;
    
    console.log('âœ… Canvas initialized:', {
      width: canvas.width,
      height: canvas.height,
      strokesCount: liveDrawingData.strokes.length
    });

    const renderFrame = () => {
      if (!isActive) return;

      const currentVideoTime = videoElement.currentTime;
      const relativeTime = currentVideoTime - startTimestamp;

      // æ¸…ç©ºç”»å¸ƒ
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // ç»˜åˆ¶æ‰€æœ‰åº”è¯¥æ˜¾ç¤ºçš„ç¬”ç”»
      liveDrawingData.strokes.forEach(stroke => {
        // åªç»˜åˆ¶å·²ç»å¼€å§‹çš„ç¬”ç”»
        if (relativeTime < stroke.startTime) return;

        const isComplete = relativeTime >= stroke.endTime;
        
        if (stroke.points.length < 2) return;

        ctx.strokeStyle = stroke.color;
        ctx.lineWidth = stroke.width;
        ctx.lineCap = 'round';
        ctx.lineJoin = 'round';

        if (stroke.tool === 'eraser') {
          ctx.globalCompositeOperation = 'destination-out';
        } else {
          ctx.globalCompositeOperation = 'source-over';
        }

        ctx.beginPath();

        if (isComplete) {
          // ç¬”ç”»å·²å®Œæˆï¼Œç»˜åˆ¶å…¨éƒ¨
          ctx.moveTo(stroke.points[0].x, stroke.points[0].y);
          for (let i = 1; i < stroke.points.length; i++) {
            ctx.lineTo(stroke.points[i].x, stroke.points[i].y);
          }
        } else {
          // ç¬”ç”»æ­£åœ¨è¿›è¡Œä¸­ï¼ŒæŒ‰æ¯”ä¾‹ç»˜åˆ¶
          const strokeDuration = stroke.endTime - stroke.startTime;
          const strokeProgress = (relativeTime - stroke.startTime) / strokeDuration;
          const pointsToShow = Math.floor(stroke.points.length * strokeProgress);

          if (pointsToShow >= 2) {
            ctx.moveTo(stroke.points[0].x, stroke.points[0].y);
            for (let i = 1; i < pointsToShow; i++) {
              ctx.lineTo(stroke.points[i].x, stroke.points[i].y);
            }
          }
        }

        ctx.stroke();
      });

      ctx.globalCompositeOperation = 'source-over';

      // ç»§ç»­ä¸‹ä¸€å¸§
      animationFrameRef.current = requestAnimationFrame(renderFrame);
    };

    // å¯åŠ¨æ¸²æŸ“å¾ªç¯
    renderFrame();

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isActive, videoElement, liveDrawingData, startTimestamp]);

  if (!isActive) return null;

  return (
    <canvas
      ref={canvasRef}
      className="absolute top-0 left-0 w-full h-full pointer-events-none"
      style={{ zIndex: 25 }}
    />
  );
};
